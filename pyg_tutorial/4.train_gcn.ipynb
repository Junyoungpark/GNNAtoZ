{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 4: Minimalistic re-implementation of Graph Convolutional Networks (GCN) in PyG\n",
    "\n",
    "In this tutorial, we will reimplement Semi-Supervised Classification with Graph Convolutional Networks (GCN) introduced by [Kipf et al. (2017)](https://arxiv.org/abs/1609.02907) with PyTorch Geometric. The following codes are inspired by an open source implementation [here](https://github.com/ki-ljl/PyG-GCN/tree/main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import Planetoid, NELL\n",
    "from torch_geometric.nn.models import GCN\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(name: str):\n",
    "    assert name in ['Cora', 'CiteSeer', 'PubMed']\n",
    "    dataset = Planetoid(root=f'/tmp/{name}', name=f'{name}')\n",
    "    return dataset \n",
    "\n",
    "def train(model, data, \n",
    "          num_epochs:int=200,\n",
    "          device:str='cpu'):\n",
    "    model = model.to(device)\n",
    "    data = data.to(device)\n",
    "    \n",
    "    opt = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    model.train() # Set model to 'train' mode\n",
    "    \n",
    "    pbar = tqdm(range(num_epochs), total=num_epochs, ascii=' =', leave=True)\n",
    "    for epoch in pbar:\n",
    "        out = model(data.x, data.edge_index)\n",
    "        opt.zero_grad()\n",
    "        loss = loss_fn(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # Progress bar\n",
    "        pbar.set_description('Epoch {:03d} loss {:.4f}'.format(epoch, loss.item()))\n",
    "        \n",
    "    model = model.to('cpu')\n",
    "\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    _, pred = model(data.x, data.edge_index).max(dim=1)\n",
    "    correct = int(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "    acc = correct / int(data.test_mask.sum())\n",
    "    print('Accuracy: {:.4f}'.format(acc))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579091ff2942466da8a71f5f170dd094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cora ---\n",
      "Accuracy: 0.6920\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc8a5f1edd89458eb658d119aa699094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CiteSeer ---\n",
      "Accuracy: 0.5120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe248b8627f4214a466066d679cd008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PubMed ---\n",
      "Accuracy: 0.7310\n"
     ]
    }
   ],
   "source": [
    "dataset_names = ['Cora', 'CiteSeer', 'PubMed']\n",
    "device = 'cuda:0'\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    dataset = get_dataset(dataset_name)\n",
    "\n",
    "    model = GCN(in_channels=dataset.num_node_features, \n",
    "                hidden_channels=32, \n",
    "                num_layers=2,\n",
    "                out_channels=dataset.num_classes,\n",
    "                dropout=0.5,\n",
    "                norm='batch', # 'batch', 'instance', 'layer', 'none'\n",
    "                )\n",
    "\n",
    "    train(model, dataset[0], device=device)\n",
    "    print(f'--- {dataset_name} ---')\n",
    "    test(model, dataset[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch200-py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
